import os
from io import BytesIO
from typing import Generator

import gradio as gr
import litserve as ls
import numpy as np
import requests
from fastapi import Response, UploadFile
from PIL import Image

from lang_sam import SAM_MODELS, LangSAM
from lang_sam.utils import draw_image

PORT = 8000


class LangSAMAPI(ls.LitAPI):
    def setup(self, device: str) -> None:
        """Initialize or load the LangSAM model."""
        self.model = LangSAM(sam_type="sam2_hiera_small")
        print("LangSAM model initialized.")

    def decode_request(self, request) -> dict:
        """
        Decode the incoming request to extract parameters and image bytes.

        Assumes the request is sent as multipart/form-data with fields:
        - sam_type: str
        - box_threshold: float
        - text_threshold: float
        - text_prompt: str
        - image: UploadFile
        """
        # Extract form data
        sam_type = request.get("sam_type")
        box_threshold = float(request.get("box_threshold", 0.3))
        text_threshold = float(request.get("text_threshold", 0.25))
        text_prompt = request.get("text_prompt", "")

        # Extract image file
        image_file: UploadFile = request.get("image")
        if image_file is None:
            raise ValueError("No image file provided in the request.")

        image_bytes = image_file.file.read()

        return {
            "sam_type": sam_type,
            "box_threshold": box_threshold,
            "text_threshold": text_threshold,
            "image_bytes": image_bytes,
            "text_prompt": text_prompt,
        }

    def predict(self, inputs: dict) -> Generator[dict, None, None]:
        """
        Perform prediction using the LangSAM model.

        Yields:
            dict: Contains the processed output image.
        """
        print("Starting prediction with parameters:")
        print(
            f"sam_type: {inputs['sam_type']}, box_threshold: {inputs['box_threshold']}, text_threshold: {inputs['text_threshold']}, text_prompt: {inputs['text_prompt']}"
        )

        # Update model type if necessary
        if inputs["sam_type"] != self.model.sam_type:
            print(f"Updating SAM model type to {inputs['sam_type']}")
            self.model.sam.build_model(inputs["sam_type"])

        # Load image from bytes
        try:
            image_pil = Image.open(BytesIO(inputs["image_bytes"])).convert("RGB")
        except Exception as e:
            raise ValueError(f"Invalid image data: {e}")

        # Perform prediction
        results = self.model.predict(
            image_pil=image_pil,
            text_prompt=inputs["text_prompt"],
            box_threshold=inputs["box_threshold"],
            text_threshold=inputs["text_threshold"],
        )

        if not len(results["masks"]):
            print("No masks detected. Returning original image.")
            yield {"output_image": image_pil}
            return

        # Draw results on the image
        image_array = np.asarray(image_pil)
        output_image = draw_image(
            image_array,
            results["masks"],
            results["boxes"],
            results["scores"],
            results["labels"],
        )
        output_image = Image.fromarray(np.uint8(output_image)).convert("RGB")

        yield {"output_image": output_image}

    def encode_response(self, output: Generator[dict, None, None]) -> Response:
        """
        Encode the prediction result into an HTTP response.

        Returns:
            Response: Contains the processed image in PNG format.
        """
        try:
            output_dict = next(output)
            image = output_dict["output_image"]
            buffer = BytesIO()
            image.save(buffer, format="PNG")
            buffer.seek(0)
            return Response(content=buffer.getvalue(), media_type="image/png")
        except StopIteration:
            raise ValueError("No output generated by the prediction.")


def inference(sam_type, box_threshold, text_threshold, image, text_prompt):
    """Gradio function that makes a request to the /predict LitServe endpoint."""
    url = f"http://localhost:{PORT}/predict"  # Adjust port if needed

    # Prepare the multipart form data
    with open(image, "rb") as img_file:
        files = {
            "image": img_file,
        }
        data = {
            "sam_type": sam_type,
            "box_threshold": str(box_threshold),
            "text_threshold": str(text_threshold),
            "text_prompt": text_prompt,
        }

        try:
            response = requests.post(url, files=files, data=data)
        except Exception as e:
            print(f"Request failed: {e}")
            return None

    if response.status_code == 200:
        try:
            output_image = Image.open(BytesIO(response.content)).convert("RGB")
            return output_image
        except Exception as e:
            print(f"Failed to process response image: {e}")
            return None
    else:
        print(f"Request failed with status code {response.status_code}: {response.text}")
        return None


# Create the Gradio interface
with gr.Blocks() as blocks:
    with gr.Row():
        sam_model_choices = gr.Dropdown(choices=list(SAM_MODELS.keys()), label="SAM Model", value="sam2_hiera_small")
        box_threshold = gr.Slider(minimum=0.0, maximum=1.0, value=0.3, label="Box Threshold")
        text_threshold = gr.Slider(minimum=0.0, maximum=1.0, value=0.25, label="Text Threshold")
    with gr.Row():
        image_input = gr.Image(type="filepath", label="Input Image")
        output_image = gr.Image(type="pil", label="Output Image")
    text_prompt = gr.Textbox(lines=1, label="Text Prompt")

    submit_btn = gr.Button("Run Prediction")

    # Define output

    submit_btn.click(
        fn=inference,
        inputs=[sam_model_choices, box_threshold, text_threshold, image_input, text_prompt],
        outputs=output_image,
    )

    examples = [
        [
            "sam2_hiera_small",
            0.36,
            0.25,
            os.path.join(os.path.dirname(__file__), "assets", "fruits.jpg"),
            "kiwi. watermelon. blueberry.",
        ],
        [
            "sam2_hiera_small",
            0.3,
            0.25,
            os.path.join(os.path.dirname(__file__), "assets", "car.jpeg"),
            "wheel.",
        ],
        [
            "sam2_hiera_small",
            0.3,
            0.25,
            os.path.join(os.path.dirname(__file__), "assets", "food.jpg"),
            "food.",
        ],
    ]

    gr.Examples(
        examples=examples,
        inputs=[sam_model_choices, box_threshold, text_threshold, image_input, text_prompt],
        outputs=output_image,
    )

lit_api = LangSAMAPI()
server = ls.LitServer(lit_api)

server.app = gr.mount_gradio_app(server.app, blocks, path="/gradio")

if __name__ == "__main__":
    print(f"Starting LitServe and Gradio server on port {PORT}...")
    server.run(port=PORT)
